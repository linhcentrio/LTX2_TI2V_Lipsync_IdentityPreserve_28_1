# ğŸ¬ LTX2 Text-to-Image-to-Video vá»›i Lipsync & Identity Preservation

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)
[![RunPod](https://img.shields.io/badge/RunPod-Serverless-orange.svg)](https://www.runpod.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **RunPod Serverless Handler** tÃ­ch há»£p ComfyUI workflow Ä‘á»ƒ táº¡o video tá»« text vá»›i **LTX-2 model**, káº¿t há»£p **lipsync** vÃ  **identity preservation**.

## ğŸŒŸ TÃ­nh NÄƒng

### âœ¨ Core Features
- ğŸ¨ **Text-to-Image-to-Video**: Text â†’ áº¢nh (Flux) â†’ Video (LTX-2)
- ğŸ­ **Identity Preservation**: Giá»¯ nguyÃªn khuÃ´n máº·t nhÃ¢n váº­t
- ğŸ¤ **Lipsync**: Äá»“ng bá»™ mÃ´i vá»›i audio (Wav2Lip)
- âš¡ **Flash-Attention 3**: Tá»‘i Æ°u CUDA 12.8 cho A100/H100
- ğŸ“¦ **S3 Storage**: Upload/download tá»± Ä‘á»™ng
- ğŸ³ **Docker Ready**: Deploy dá»… dÃ ng trÃªn RunPod

### ğŸš€ Technical Stack
- **LTX-2**: MÃ´ hÃ¬nh video generation má»›i nháº¥t
- **Flux**: Text-to-Image quality cao
- **ComfyUI**: Visual workflow engine
- **RunPod Serverless**: Scalable GPU inference
- **Flash-Attention 3**: 2-3x faster training/inference

## ğŸ“‹ YÃªu Cáº§u Há»‡ Thá»‘ng

### Hardware
- **GPU**: NVIDIA A100 (40GB/80GB) hoáº·c H100
- **VRAM**: Tá»‘i thiá»ƒu 24GB
- **RAM**: 32GB+
- **Storage**: 100GB+ SSD

### Software
- **CUDA**: 12.8+
- **Python**: 3.10+
- **Docker**: 24.0+
- **ComfyUI**: Latest version

## ğŸ”§ CÃ i Äáº·t

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/linhcentrio/LTX2_TI2V_Lipsync_IdentityPreserve_28_1.git
cd LTX2_TI2V_Lipsync_IdentityPreserve_28_1
```

### 2ï¸âƒ£ CÃ i Äáº·t Dependencies

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# Install packages
pip install -r requirements.txt
```

### 3ï¸âƒ£ Setup Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env vá»›i credentials cá»§a báº¡n
nano .env
```

### 4ï¸âƒ£ Download Models

```bash
# LTX-2 model
wget -P models/ https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltx-video-2b-v0.9.safetensors

# Flux model
wget -P models/ https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors

# Lipsync models
wget -P models/ https://github.com/Rudrabha/Wav2Lip/releases/download/v1.0/wav2lip.pth
```

## ğŸ³ Docker Deployment

### Build Image

```bash
# Build Docker image
docker build -t ltx2-lipsync:latest .

# Or use docker-compose
docker-compose build
```

### Run Container

```bash
# Run with docker-compose
docker-compose up -d

# Or manual docker run
docker run -d \
  --gpus all \
  -p 8188:8188 \
  -v $(pwd)/models:/workspace/models \
  -v $(pwd)/output:/workspace/output \
  --env-file .env \
  ltx2-lipsync:latest
```

## ğŸš€ RunPod Deployment

### Deploy to RunPod Serverless

```bash
# Login to RunPod
runpodctl login

# Deploy endpoint
runpodctl deploy \
  --name ltx2-lipsync \
  --image your-dockerhub-username/ltx2-lipsync:latest \
  --gpu-type "NVIDIA A100" \
  --gpu-count 1 \
  --min-workers 0 \
  --max-workers 3
```

### Test Endpoint

```python
import runpod

# Configure endpoint
runpod.api_key = "your-runpod-api-key"
endpoint = runpod.Endpoint("ENDPOINT_ID")

# Run inference
result = endpoint.run({
    "input": {
        "prompt": "A beautiful woman talking about AI technology",
        "audio_url": "https://example.com/audio.mp3",
        "reference_image_url": "https://example.com/face.jpg",
        "num_frames": 120,
        "fps": 24
    }
})

print(f"Video URL: {result['output']['video_url']}")
```

## ğŸ“– API Documentation

### Input Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | âœ… | Text mÃ´ táº£ video |
| `audio_url` | string | âœ… | URL file audio (.mp3, .wav) |
| `reference_image_url` | string | âŒ | URL áº£nh khuÃ´n máº·t tham chiáº¿u |
| `num_frames` | integer | âŒ | Sá»‘ frames (default: 120) |
| `fps` | integer | âŒ | FPS (default: 24) |
| `width` | integer | âŒ | Chiá»u rá»™ng (default: 512) |
| `height` | integer | âŒ | Chiá»u cao (default: 768) |
| `cfg_scale` | float | âŒ | CFG scale (default: 7.0) |
| `steps` | integer | âŒ | Sá»‘ steps (default: 30) |
| `seed` | integer | âŒ | Random seed (default: -1) |

### Output Format

```json
{
  "status": "success",
  "output": {
    "video_url": "https://s3.amazonaws.com/bucket/video_123.mp4",
    "duration": 5.0,
    "fps": 24,
    "frames": 120,
    "resolution": "512x768",
    "file_size": 15728640
  },
  "metadata": {
    "processing_time": 45.2,
    "gpu_time": 38.5,
    "model_version": "ltx-2-v0.9",
    "timestamp": "2026-01-30T15:30:00Z"
  }
}
```

## ğŸ“ Project Structure

```
LTX2_TI2V_Lipsync_IdentityPreserve_28_1/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ rp_handler.py            # RunPod serverless handler
â”‚   â”œâ”€â”€ comfyui_api.py           # ComfyUI API client
â”‚   â”œâ”€â”€ storage.py               # S3 storage manager
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ ltx2_i2v_lipsync.json    # ComfyUI workflow definition
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_handler.py          # Unit tests
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml           # CI/CD pipeline
â”œâ”€â”€ models/                       # Model storage (gitignored)
â”œâ”€â”€ output/                       # Output videos (gitignored)
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ docker-compose.yml           # Docker Compose setup
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”œâ”€â”€ LICENSE                      # MIT License
â””â”€â”€ README.md                    # This file
```

## ğŸ§ª Testing

### Run Unit Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Test specific file
pytest tests/test_handler.py -v
```

### Local Testing

```bash
# Start ComfyUI
cd /path/to/ComfyUI
python main.py --listen 0.0.0.0 --port 8188

# Test handler locally
python -c "
import json
from src.rp_handler import handler

job = {
    'input': {
        'prompt': 'A woman explaining AI concepts',
        'audio_url': 'https://example.com/audio.mp3'
    }
}

result = handler(job)
print(json.dumps(result, indent=2))
"
```

## ğŸ¯ Workflow Details

### Pipeline Steps

1. **Text-to-Image** (Flux)
   - Input: Text prompt
   - Output: High-quality image (512x768)

2. **Image-to-Video** (LTX-2)
   - Input: Generated image + prompt
   - Output: Video frames (120 frames @ 24fps)

3. **Lipsync** (Wav2Lip)
   - Input: Video + Audio
   - Output: Synced video vá»›i lip movement

4. **Identity Preservation**
   - Face detection & tracking
   - Identity consistency across frames

### Performance Benchmarks

| GPU | Resolution | Frames | Time | Cost/Run |
|-----|------------|--------|------|----------|
| A100 40GB | 512x768 | 120 | ~45s | $0.08 |
| A100 80GB | 768x1024 | 240 | ~90s | $0.15 |
| H100 | 1024x1024 | 240 | ~60s | $0.20 |

## ğŸ” Security

### Environment Variables

KhÃ´ng commit file `.env` chá»©a credentials. Sá»­ dá»¥ng `.env.example` lÃ m template.

### S3 Permissions

Cáº¥u hÃ¬nh IAM role vá»›i permissions tá»‘i thiá»ƒu:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": "arn:aws:s3:::your-bucket/*"
    }
  ]
}
```

## ğŸ› Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory

```bash
# Giáº£m batch size hoáº·c resolution
# Trong workflow JSON, Ä‘iá»u chá»‰nh:
"batch_size": 1
"width": 512
"height": 512
```

#### 2. ComfyUI Connection Failed

```bash
# Kiá»ƒm tra ComfyUI Ä‘ang cháº¡y
curl http://localhost:8188/system_stats

# Restart ComfyUI
pkill -f "python.*main.py"
cd /workspace/ComfyUI && python main.py --listen 0.0.0.0
```

#### 3. Model Loading Error

```bash
# Verify model files
ls -lh models/*.safetensors

# Re-download if corrupted
rm models/ltx-video-2b-v0.9.safetensors
wget -P models/ [model_url]
```

## ğŸ“Š Monitoring

### Logs

```bash
# View RunPod logs
runpodctl logs ENDPOINT_ID

# Docker logs
docker-compose logs -f

# Application logs
tail -f /workspace/logs/app.log
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“œ License

Distributed under MIT License. See `LICENSE` for more information.

## ğŸ‘¤ Author

**Há»“ Máº¡nh Linh** - [@linhcentrio](https://github.com/linhcentrio)

- Company: CentrioShop
- GitHub: [linhcentrio](https://github.com/linhcentrio)

## ğŸ™ Acknowledgments

- [LTX-2](https://github.com/Lightricks/LTX-Video) - Video generation model
- [Flux](https://github.com/black-forest-labs/flux) - Text-to-Image
- [ComfyUI](https://github.com/comfyanonymous/ComfyUI) - Workflow engine
- [Wav2Lip](https://github.com/Rudrabha/Wav2Lip) - Lipsync technology
- [RunPod](https://www.runpod.io/) - GPU infrastructure

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», vui lÃ²ng:
- Open [GitHub Issue](https://github.com/linhcentrio/LTX2_TI2V_Lipsync_IdentityPreserve_28_1/issues)
- Email: support@example.com

---

â­ **Star project nÃ y náº¿u báº¡n tháº¥y há»¯u Ã­ch!** â­